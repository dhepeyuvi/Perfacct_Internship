{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Extensions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Base Libraries\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from utility_scripts import utils\n",
    "import os\n",
    "\n",
    "\n",
    "# DL Base Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as tf_app\n",
    "from tensorflow.keras.applications.mobilenet_v3 import (\n",
    "    preprocess_input,\n",
    "    decode_predictions,\n",
    ")\n",
    "from EMA import (\n",
    "    EMA_finalize,\n",
    "    EMA_init,\n",
    ")\n",
    "\n",
    "# Use GPUS as is Required\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = int(input(\"\\n\\nIf using a jnb enter 1 else 0\\n\"))\n",
    "uni = int(input(\"\\n\\nIf using uni gpu enter 1 else 0\\n\"))\n",
    "gpu_id = int(\n",
    "    input(\"\\n\\n Which GPU to USE enter the GPU index of nvidia-smi\\n\")\n",
    ")\n",
    "# If everything is run from jupyter nb then results file generated will have a suffix of uni\n",
    "\n",
    "results_suffix = \"uni\" if uni else \"work\"\n",
    "results_suffix += \"_nb\" if nb else \"_py\"\n",
    "print(f\"Suffix used with result files will be {results_suffix}!!\")\n",
    "\n",
    "\n",
    "GPU_ID = gpu_id\n",
    "print(f\"GPU: {GPU_ID} is being used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model names and directories for saving\n",
    "model_name = \"MobileNetV3L\"\n",
    "models_directory = \"models_lib\"\n",
    "results_directory = \"benchmark_results\"\n",
    "\n",
    "model_type = \"tf_models\"\n",
    "model_save_path = os.path.join(models_directory, model_type)\n",
    "results_save_path = os.path.join(results_directory, model_name)\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    print(f\"Save Path {model_save_path} doesn't exist Creating!!\")\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "if not os.path.exists(results_save_path):\n",
    "    print(f\"Results Dir {results_save_path} doesn't exist Creating!!\")\n",
    "    os.makedirs(results_save_path, exist_ok=True)\n",
    "\n",
    "url = \"https://i.pinimg.com/originals/56/ea/2b/56ea2bb991a7446776ac2f2f27fdc397.jpg\"\n",
    "num_images = 512\n",
    "# url = \"https://images.dog.ceo/breeds/retriever-golden/n02099601_3004.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "tf_model = tf_app.MobileNetV3Large(weights=\"imagenet\", include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "# EMA_init()\n",
    "img = resize(io.imread(url), (224, 224))\n",
    "img = 255 * np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "preds = tf_model.predict(img)\n",
    "print(f\"Predicted {decode_predictions(preds, top = 3)[0]}\")\n",
    "plt.imshow(img[0] / 255)\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "plt.axis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_model.save(os.path.join(model_save_path, model_name))\n",
    "# tf_model.save(f\"{os.path.join(model_save_path, model_name)}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.load_model(\n",
    "    os.path.join(model_save_path, model_name)\n",
    ")\n",
    "keras_model = tf.keras.models.load_model(\n",
    "    f\"{os.path.join(model_save_path, model_name)}.keras\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making some preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading n preprocessing the image\n",
    "\n",
    "img = resize(io.imread(url), (224, 224))\n",
    "img = 255 * np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "preds = keras_model(img).numpy()\n",
    "print(f\"Predicted {decode_predictions(preds, top = 3)[0]}\")\n",
    "plt.imshow(img[0] / 255)\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "plt.axis()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "xla_enabled_model = tf.function(keras_model)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "preds = xla_enabled_model(img).numpy()\n",
    "print(f\"Predicted {decode_predictions(preds, top = 3)[0]}\")\n",
    "plt.imshow(img[0] / 255)\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "plt.axis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Doing one prediction is necessary to compile the model\n",
    "# Loading n preprocessing the image\n",
    "\n",
    "img = resize(io.imread(url), (224, 224))\n",
    "img = 255 * np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "preds = tf_model(img).numpy()\n",
    "print(f\"Predicted {decode_predictions(preds, top = 3)[0]}\")\n",
    "plt.imshow(img[0] / 255)\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "plt.axis()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "xla_enabled_model = tf.function(tf_model)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "preds = xla_enabled_model(img).numpy()\n",
    "print(f\"Predicted {decode_predictions(preds, top = 3)[0]}\")\n",
    "plt.imshow(img[0] / 255)\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "plt.axis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow H5 Model Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization of EMA\n",
    "EMA_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(url)\n",
    "input_data, _ = utils.batch_sigle_img(\n",
    "    img,\n",
    "    target_size=(224, 224),\n",
    "    num_images=num_images,\n",
    "    preprocessor=preprocess_input,\n",
    ")\n",
    "input_data = input_data.astype(np.float32)\n",
    "num_warmup_runs = 50\n",
    "num_model_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"tf_{num_model_runs}_it_{results_suffix}.csv\"\n",
    "csv_save_path = os.path.join(results_save_path, fname)\n",
    "\n",
    "utils.batch_model_performances(\n",
    "    framework_name=\"tf\",\n",
    "    model=tf_model,\n",
    "    input_data=input_data,\n",
    "    batch_sizes=[8, 16, 32, 64, 128, 256, 512],\n",
    "    csv_path=csv_save_path,\n",
    "    num_warmup_runs=num_warmup_runs,\n",
    "    num_model_runs=num_model_runs,\n",
    "    trt=False,\n",
    "    onnx=False,\n",
    "    torch=False,\n",
    "    gpu_id=GPU_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Remember to export xargs\n",
    "fname = f\"tfxla_{num_model_runs}_it_{results_suffix}.csv\"\n",
    "csv_save_path = os.path.join(results_save_path, fname)\n",
    "\n",
    "xla_enabled_model = tf.function(tf_model)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "utils.batch_model_performances(\n",
    "    framework_name=\"tfxla\",\n",
    "    model=xla_enabled_model,\n",
    "    input_data=input_data,\n",
    "    batch_sizes=[8, 16, 32, 64, 128, 256, 512],\n",
    "    csv_path=csv_save_path,\n",
    "    num_warmup_runs=num_warmup_runs,\n",
    "    num_model_runs=num_model_runs,\n",
    "    trt=False,\n",
    "    onnx=False,\n",
    "    torch=False,\n",
    "    gpu_id=GPU_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"keras_{num_model_runs}_it_{results_suffix}.csv\"\n",
    "csv_save_path = os.path.join(results_save_path, fname)\n",
    "utils.batch_model_performances(\n",
    "    framework_name=\"keras\",\n",
    "    model=keras_model,\n",
    "    input_data=input_data,\n",
    "    batch_sizes=[8, 16, 32, 64, 128, 256, 512],\n",
    "    csv_path=csv_save_path,\n",
    "    num_warmup_runs=num_warmup_runs,\n",
    "    num_model_runs=num_model_runs,\n",
    "    trt=False,\n",
    "    onnx=False,\n",
    "    torch=False,\n",
    "    gpu_id=GPU_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Remember to export xargs\n",
    "fname = f\"kerasxla_{num_model_runs}_it_{results_suffix}.csv\"\n",
    "csv_save_path = os.path.join(results_save_path, fname)\n",
    "\n",
    "xla_enabled_model = tf.function(keras_model)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "utils.batch_model_performances(\n",
    "    framework_name=\"kerasxla\",\n",
    "    model=xla_enabled_model,\n",
    "    input_data=input_data,\n",
    "    batch_sizes=[8, 16, 32, 64, 128, 256, 512],\n",
    "    csv_path=csv_save_path,\n",
    "    num_warmup_runs=num_warmup_runs,\n",
    "    num_model_runs=num_model_runs,\n",
    "    trt=False,\n",
    "    onnx=False,\n",
    "    torch=False,\n",
    "    gpu_id=GPU_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finishing the EMA\n",
    "EMA_finalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
